{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with BeautifulSoup\n",
    "\n",
    "Web scraping is the process of extracting data from websites. This notebook explains how to perform web scraping using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "    Python (3.x)\n",
    "    BeautifulSoup library\n",
    "    lxml parser (optional but recommended for performance)\n",
    "\n",
    "You can install the required libraries using pip:\n",
    "`\n",
    "pip install beautifulsoup4 lxml\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here, We use BeautifulSoup to scrap [Grocery Shope](https://Sivasuthan9.github.io/Web-scraping/grocery_shop.html) which represents a grocery shop.\n",
    "Checkout the HTML content of it in Web Scraping/grocery_shop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open and read the HTML file\n",
    "with open(\"grocery_shop.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup parses the HTML with the lxml parser\n",
    "\n",
    "Below uses the lxml parser to break down the HTML structure and convert it into an object (the soup object) that allows you to:\n",
    "Traverse the HTML tree (its structure),\n",
    "Access and manipulate HTML tags and elements in a Pythonic way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #The content is parsed with lxml to create a BeautifulSoup object.\n",
    "soup = BeautifulSoup(content, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Data \n",
    "It loops through each card and checks if the header includes the text \"(Fruit)\".\n",
    "If so, it extracts the fruit name (inside the <strong> tag) and the price from the button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruit: Apple, Price: $2/kg\n",
      "Fruit: Banana, Price: $1/kg\n",
      "Fruit: Orange, Price: $2.5/kg\n",
      "Fruit: Grapes, Price: $3/kg\n"
     ]
    }
   ],
   "source": [
    "# Find all cards related to fruits and get their names and prices\n",
    "fruits = []\n",
    "\n",
    "# Loop through all cards\n",
    "for card in soup.find_all(\"div\", class_=\"card\"):\n",
    "    header = card.find(\"div\", class_=\"card-header\")\n",
    "    if header and \"(Fruit)\" in header.text:\n",
    "        name = header.strong.text.strip()  # Get the fruit name in bold\n",
    "        price_text = card.find(\"a\", class_=\"btn btn-primary\").text.strip()\n",
    "        price = price_text.split(\" \")[-1]  # Extract the price part (e.g., \"$2/kg\")\n",
    "        fruits.append((name, price))\n",
    "\n",
    "# Print out the fruits and their prices\n",
    "for fruit, price in fruits:\n",
    "    print(f\"Fruit: {fruit}, Price: {price}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
